{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T22:27:14.300911Z","iopub.status.busy":"2024-02-04T22:27:14.300561Z","iopub.status.idle":"2024-02-04T22:27:18.093889Z","shell.execute_reply":"2024-02-04T22:27:18.092850Z","shell.execute_reply.started":"2024-02-04T22:27:14.300880Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import numpy as np\n","import scipy.sparse as sp\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation"]},{"cell_type":"markdown","metadata":{},"source":["### Cora Dataset\n","\n","To test on a smaller dataset first"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T22:27:18.989802Z","iopub.status.busy":"2024-02-04T22:27:18.989330Z","iopub.status.idle":"2024-02-04T22:27:18.998116Z","shell.execute_reply":"2024-02-04T22:27:18.996365Z","shell.execute_reply.started":"2024-02-04T22:27:18.989768Z"},"trusted":true},"outputs":[],"source":["def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","\n","    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    # get the indices of non-zero elements in the coo matrix\n","    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    # get the non-zero elements of the sparse matrix\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","\n","    return torch.sparse.FloatTensor(indices, values, shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T21:18:02.230766Z","iopub.status.busy":"2024-02-04T21:18:02.230097Z","iopub.status.idle":"2024-02-04T21:18:02.235684Z","shell.execute_reply":"2024-02-04T21:18:02.234603Z","shell.execute_reply.started":"2024-02-04T21:18:02.230731Z"},"trusted":true},"outputs":[],"source":["def parse_index_file(filename):\n","    \"\"\"Parse index file.\"\"\"\n","    index = []\n","    for line in open(filename):\n","        index.append(int(line.strip()))\n","    return index"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T21:25:51.960860Z","iopub.status.busy":"2024-02-04T21:25:51.960365Z","iopub.status.idle":"2024-02-04T21:25:52.636797Z","shell.execute_reply":"2024-02-04T21:25:52.635790Z","shell.execute_reply.started":"2024-02-04T21:25:51.960821Z"},"trusted":true},"outputs":[],"source":["import pickle\n","import scipy.sparse as sp\n","import numpy as np\n","import torch\n","from sklearn.preprocessing import LabelEncoder\n","import sys\n","\n","def load_data(dataset_str):\n","    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n","    objects = []\n","    for i in range(len(names)):\n","        with open(\"/kaggle/input/cora-data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n","            if sys.version_info > (3, 0):\n","                objects.append(pickle.load(f, encoding='latin1'))\n","            else:  # python2\n","                objects.append(pickle.load(f))\n","\n","    x, y, tx, ty, allx, ally, graph = tuple(objects)\n","\n","    test_idx_reorder = parse_index_file(\"/kaggle/input/cora-data/ind.{}.test.index\".format(dataset_str))\n","    test_idx_range = np.sort(test_idx_reorder)\n","    \n","    # construct labels vector\n","    labels = np.vstack((ally, ty))\n","    labels = np.where(labels)[1]\n","    labels = torch.LongTensor(labels)\n","    \n","    # construct feature matrix\n","    features = sp.vstack((allx, tx)).tolil()\n","    features[test_idx_reorder, :] = features[test_idx_range, :]\n","    feature_matrix = torch.FloatTensor(np.array(features.todense()))\n","\n","    # construct adjacency matrix\n","    num_nodes = features.shape[0]\n","    adj = sp.lil_matrix((num_nodes, num_nodes))\n","    for i in range(num_nodes):\n","        adj[i, graph[i]] = 1\n","        adj[graph[i], i] = 1\n","\n","    # construct symmetric normalized laplacian\n","    rowsum = np.array(adj.sum(1))\n","    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","    laplacian = adj.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","\n","    # convert scipy sparse adjacency matrix to torch sparse tensor\n","    laplacian = sparse_mx_to_torch_sparse_tensor(laplacian)\n","    \n","    # construct train, validation, test split\n","    idx_test = test_idx_range.tolist()\n","    idx_train = range(len(y))\n","    idx_val = range(len(y), len(y) + 500)\n","    \n","    idx_train = torch.LongTensor(idx_train)\n","    idx_val = torch.LongTensor(idx_val)\n","    idx_test = torch.LongTensor(idx_test)\n","\n","    \n","    return laplacian, feature_matrix, labels, idx_train, idx_val, idx_test\n","\n","\n","laplacian, feature_matrix, labels, idx_train, idx_val, idx_test = load_data('cora')"]},{"cell_type":"markdown","metadata":{},"source":["## OGB Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T22:27:37.039225Z","iopub.status.busy":"2024-02-04T22:27:37.038798Z","iopub.status.idle":"2024-02-04T22:55:39.150337Z","shell.execute_reply":"2024-02-04T22:55:39.149041Z","shell.execute_reply.started":"2024-02-04T22:27:37.039187Z"},"trusted":true},"outputs":[],"source":["# this worked\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T22:55:39.153783Z","iopub.status.busy":"2024-02-04T22:55:39.152913Z","iopub.status.idle":"2024-02-04T22:55:54.770362Z","shell.execute_reply":"2024-02-04T22:55:54.769239Z","shell.execute_reply.started":"2024-02-04T22:55:39.153741Z"},"trusted":true},"outputs":[],"source":["!pip install ogb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:12:09.533019Z","iopub.status.busy":"2024-02-04T23:12:09.531829Z","iopub.status.idle":"2024-02-04T23:12:13.786915Z","shell.execute_reply":"2024-02-04T23:12:13.785929Z","shell.execute_reply.started":"2024-02-04T23:12:09.532976Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["from ogb.nodeproppred import PygNodePropPredDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:12:13.789833Z","iopub.status.busy":"2024-02-04T23:12:13.788683Z","iopub.status.idle":"2024-02-04T23:12:29.244145Z","shell.execute_reply":"2024-02-04T23:12:29.243309Z","shell.execute_reply.started":"2024-02-04T23:12:13.789795Z"},"trusted":true},"outputs":[],"source":["dataset = PygNodePropPredDataset(name='ogbn-arxiv')\n","\n","# Get features and labels from dataset\n","\n","data = dataset[0]\n","features = data.x\n","labels = data.y.squeeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:13:44.537189Z","iopub.status.busy":"2024-02-04T23:13:44.536156Z","iopub.status.idle":"2024-02-04T23:13:44.542397Z","shell.execute_reply":"2024-02-04T23:13:44.541242Z","shell.execute_reply.started":"2024-02-04T23:13:44.537144Z"},"trusted":true},"outputs":[],"source":["num_nodes = data.num_nodes\n","num_edges = data.edge_index.shape[1]\n","num_features = features.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:14:58.654657Z","iopub.status.busy":"2024-02-04T23:14:58.654008Z","iopub.status.idle":"2024-02-04T23:14:59.143799Z","shell.execute_reply":"2024-02-04T23:14:59.142769Z","shell.execute_reply.started":"2024-02-04T23:14:58.654627Z"},"trusted":true},"outputs":[],"source":["\n","\n","# create adjacency matrix as a scipy sparse matrix\n","adj = sp.coo_matrix((np.ones(data.edge_index.shape[1]), (data.edge_index[0], data.edge_index[1])), shape=(data.num_nodes, data.num_nodes), dtype=np.float32)\n","\n","# self-loop edges and symmetrically normalize adjacency matrix\n","adj = adj + sp.eye(data.num_nodes)\n","rowsum = np.array(adj.sum(1))\n","degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","laplacian = adj.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","\n","# convert scipy sparse adjacency matrix to torch sparse tensor\n","laplacian = sparse_mx_to_torch_sparse_tensor(laplacian)\n","\n","# features\n","num_features = features.shape[1]\n","feature_matrix = features # the features are already in the form of a tensor\n","\n","# labesl are already in the form of a long tensor with integer encoded labels\n","labels = labels\n","\n","# get index splits \n","idx_split = dataset.get_idx_split()\n","idx_train = idx_split['train']\n","idx_val = idx_split['valid']\n","idx_test = idx_split['test']\n","\n","num_nodes = dataset.num_nodes\n","\n","# get masks\n","train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","train_mask[idx_train] = True\n","val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","val_mask[idx_val] = True\n","test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","test_mask[idx_test] = True\n"]},{"cell_type":"markdown","metadata":{},"source":["## Sampler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:15:01.286634Z","iopub.status.busy":"2024-02-04T23:15:01.285981Z","iopub.status.idle":"2024-02-04T23:15:01.297666Z","shell.execute_reply":"2024-02-04T23:15:01.296715Z","shell.execute_reply.started":"2024-02-04T23:15:01.286603Z"},"trusted":true},"outputs":[],"source":["def ladies_sampling(laplacian, n_sample, batch_nodes, layers):\n","\n","    # input: laplacian matrix, sample size, batch nodes, number of layers\n","\n","    # output modified laplacians and sampled nodes\n","    n_nodes = laplacian.shape[0]\n","\n","    # initialize sampled nodes of last layer\n","    sampled_nodes = batch_nodes\n","    # write sampled nodes as a row selection matrix\n","    Q = torch.zeros(len(sampled_nodes), n_nodes)\n","    Q[range(len(sampled_nodes)), sampled_nodes] = 1\n","\n","    # initialize modified laplacians\n","    modified_laplacians = []\n","\n","    # iterate over layers\n","    for l in range(layers):\n","\n","        # get layer dependent laplacian \n","\n","        layer_laplacian = torch.sparse.mm(laplacian, Q.t())\n","        layer_laplacian = layer_laplacian.t()\n","\n","\n","        # compute probabilities of nodes\n","        probs = torch.sum(layer_laplacian ** 2, dim=0) / torch.sum(layer_laplacian ** 2)\n","        #print(probs.shape, 'probs shape')\n","\n","        indices = torch.arange(probs.shape[0])\n","        indices = torch.stack((indices, indices))  # Stack the indices into a 2D tensor\n","        S_sparse = torch.sparse_coo_tensor(indices=indices, values=probs, size=(probs.shape[0], probs.shape[0]))\n","\n","\n","        s_l = min(n_sample, torch.sum(probs > 0).item())\n","\n","        # sample for previous layer using probabilities\n","        sampled_nodes = np.random.choice(n_nodes, size=s_l, replace=True, p=probs.numpy())\n","\n","        # write sampled nodes as a row selection matrix\n","        Q_previous = torch.zeros(s_l, n_nodes)\n","        Q_previous[range(s_l), sampled_nodes] = 1\n","\n","        # compute modified laplacian\n","        modified_laplacian = torch.sparse.mm(layer_laplacian, S_sparse)\n","        modified_laplacian = torch.sparse.mm(modified_laplacian, Q_previous.t())\n","        \n","\n","        Q = Q_previous\n","       \n","        # append modified laplacian\n","        modified_laplacians.append(modified_laplacian) \n","        \n","    \n","    modified_laplacians.reverse()\n","    \n","    return modified_laplacians, sampled_nodes, batch_nodes    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fastgcn_sampler(laplacian, n_sample, batch_nodes, layers):\n","\n","    n_nodes = laplacian.shape[0]\n","\n","    # initialize sampled nodes of last layer\n","    sampled_nodes = batch_nodes\n","\n","    # initialize modified laplacians\n","    modified_laplacians = []\n","\n","    \n","    Q = torch.zeros(len(sampled_nodes), n_nodes)\n","    Q[range(len(sampled_nodes)), sampled_nodes] = 1\n","\n","    \n","    p = torch.sum(laplacian ** 2, dim=0) / torch.sum(laplacian ** 2)\n","\n","    \n","    S = torch.sparse_coo_tensor(torch.stack((torch.arange(p.shape[0]), torch.arange(p.shape[0]))), p, (p.shape[0], p.shape[0]))\n","    \n","\n","    # top-down sampling using probabilities \n","\n","    for l in range(layers):\n","\n","        # row selction of laplacian using Q\n","        layer_laplacian = torch.sparse.mm(laplacian, Q.t())\n","        layer_laplacian = layer_laplacian.t()\n","\n","        # sample based on probabilities p\n","        s_l = min(n_sample, torch.sum(p > 0).item())\n","\n","        sampled_nodes = np.random.choice(n_nodes, size=s_l, replace=True, p=p.numpy())\n","\n","        # write sampled nodes as a row selection matrix Q_previous\n","        Q_previous = torch.zeros(s_l, n_nodes)\n","        Q_previous[range(s_l), sampled_nodes] = 1\n","\n","        # compute modified laplacian\n","        modified_laplacian = torch.sparse.mm(layer_laplacian, S)\n","        modified_laplacian = torch.sparse.mm(modified_laplacian, Q_previous.t())\n","\n","        # update Q\n","        Q = Q_previous\n","\n","        # append modified laplacian\n","        modified_laplacians.append(modified_laplacian)\n","\n","    # reverse modified laplacians\n","    modified_laplacians.reverse()\n","\n","    return modified_laplacians, sampled_nodes, batch_nodes\n","  "]},{"cell_type":"markdown","metadata":{},"source":["## GCN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:15:06.500407Z","iopub.status.busy":"2024-02-04T23:15:06.499554Z","iopub.status.idle":"2024-02-04T23:15:06.510267Z","shell.execute_reply":"2024-02-04T23:15:06.509293Z","shell.execute_reply.started":"2024-02-04T23:15:06.500374Z"},"trusted":true},"outputs":[],"source":["class GraphConvolution(nn.Module):\n","    def __init__(self, in_features, out_features, bias=True):\n","        super(GraphConvolution, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = nn.Linear(in_features, out_features, bias=bias)\n","        \n","    def forward(self, input, adj):\n","        \n","        output = self.weight(input)\n","        output = torch.spmm(adj, output)\n","        output = F.relu(output)\n","\n","        return output\n","    \n","class GCN(nn.Module):\n","    def __init__(self, n_features, n_hidden, n_layers, dropout):\n","        super(GCN, self).__init__()\n","        self.n_features = n_features\n","        self.n_hidden = n_hidden\n","        self.n_layers = n_layers\n","\n","        self.gcn = nn.ModuleList()\n","        self.gcn.append(GraphConvolution(n_features, n_hidden))\n","        for i in range(n_layers - 1):\n","            self.gcn.append(GraphConvolution(n_hidden, n_hidden))\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def forward(self, x, laplacians):\n","\n","        # x: input feature matrix\n","        # laplacians: list of modified laplacian matrices\n","\n","        for i in range(self.n_layers):\n","            #print(x.shape)\n","            #print(laplacians[i].shape)\n","            x = self.gcn[i](x, laplacians[i])\n","            x = self.dropout(x)\n","        output = torch.log_softmax(x, dim=1)\n","        #print('output shape', x.shape)\n","        \n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T08:39:36.206740Z","iopub.status.busy":"2024-02-05T08:39:36.206068Z","iopub.status.idle":"2024-02-05T08:39:36.212974Z","shell.execute_reply":"2024-02-05T08:39:36.212109Z","shell.execute_reply.started":"2024-02-05T08:39:36.206709Z"},"trusted":true},"outputs":[],"source":["model = GCN(n_features=feature_matrix.shape[1], n_hidden=256, n_layers=2, dropout=0.5)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T08:39:38.400589Z","iopub.status.busy":"2024-02-05T08:39:38.399827Z","iopub.status.idle":"2024-02-05T08:39:38.405501Z","shell.execute_reply":"2024-02-05T08:39:38.404586Z","shell.execute_reply.started":"2024-02-05T08:39:38.400557Z"},"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:15:21.894026Z","iopub.status.busy":"2024-02-04T23:15:21.893038Z","iopub.status.idle":"2024-02-04T23:15:21.899408Z","shell.execute_reply":"2024-02-04T23:15:21.898451Z","shell.execute_reply.started":"2024-02-04T23:15:21.893984Z"},"trusted":true},"outputs":[],"source":["# accuracy function\n","\n","def accuracy(output, labels):\n","\n","    # output: output of model\n","    # labels: labels of nodes\n","\n","    preds = output.max(1)[1].type_as(labels)\n","    correct = preds.eq(labels).double()\n","    correct = correct.sum()\n","\n","    return correct / len(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T21:22:41.032670Z","iopub.status.busy":"2024-02-04T21:22:41.032285Z","iopub.status.idle":"2024-02-04T21:22:41.038889Z","shell.execute_reply":"2024-02-04T21:22:41.037870Z","shell.execute_reply.started":"2024-02-04T21:22:41.032640Z"},"trusted":true},"outputs":[],"source":["# sequential sampling\n","\n","def prepare_batches(num_batches, idx_train, n_sample, layers, batch_size):\n","    batches = []\n","    #shuffle training nodes\n","    idx_train = idx_train[torch.randperm(len(idx_train))]\n","    for i in range(num_batches):\n","        print('working')\n","        batch_nodes = idx_train[i * batch_size:(i + 1) * batch_size]\n","        modified_laplacians, sampled_nodes, batch_nodes = ladies_sampling(laplacian, n_sample, batch_nodes, layers)\n","        batches.append((modified_laplacians, sampled_nodes, batch_nodes))\n","    return batches\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T23:15:29.570828Z","iopub.status.busy":"2024-02-04T23:15:29.569808Z","iopub.status.idle":"2024-02-04T23:15:29.578363Z","shell.execute_reply":"2024-02-04T23:15:29.577262Z","shell.execute_reply.started":"2024-02-04T23:15:29.570786Z"},"trusted":true},"outputs":[],"source":["# parallel sampling\n","\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def prepare_batches_parallel(num_batches, idx_train, n_sample, layers, batch_size):\n","    batches = []\n","    idx_train = idx_train[torch.randperm(len(idx_train))]\n","\n","    with ThreadPoolExecutor() as executor:\n","        results = list(executor.map(lambda i: ladies_sampling(laplacian, n_sample, idx_train[i * batch_size:(i + 1) * batch_size], layers), range(num_batches)))\n","\n","    for result in results:\n","        batches.append(result)\n","\n","    return batches"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:50:52.364596Z","iopub.status.busy":"2024-02-04T17:50:52.364207Z","iopub.status.idle":"2024-02-04T17:50:52.397188Z","shell.execute_reply":"2024-02-04T17:50:52.395950Z","shell.execute_reply.started":"2024-02-04T17:50:52.364563Z"},"trusted":true},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T08:39:52.842236Z","iopub.status.busy":"2024-02-05T08:39:52.841847Z"},"trusted":true},"outputs":[],"source":["## training with  sequential sampling\n","import time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","batch_size = 512\n","num_batches = len(idx_train) // batch_size\n","if len(idx_train) % batch_size != 0:\n","    num_batches += 1\n","    \n","num_epochs = 10\n","\n","best_f1 = 0.0\n","\n","for epoch in range(1, num_epochs):\n","\n","    print('Epoch: {}'.format(epoch))\n","    \n","    start_time = time.time() \n","    \n","    batches = prepare_batches_parallel(num_batches, idx_train, n_sample=512, layers=2, batch_size=512)\n","    \n","    # set model to training mode\n","    model.train()\n","\n","    train_loss = []\n","    train_acc = []\n","\n","    # iterate over training batches\n","\n","    for i in range(num_batches):\n","\n","        #print('batch running', i)\n","        \n","        #sampled_laplacians, sampled_nodes, batch_nodes = ladies_sampling(laplacian, n_sample=4, batch_nodes=batch, layers=2)\n","        sampled_laplacians, sampled_nodes, batch_nodes = batches[i]\n","        \n","        optimizer.zero_grad()\n","\n","        feature_matrix_sampled = feature_matrix[sampled_nodes].to(device)\n","\n","        sampled_laplacians = [laplacian.to(device) for laplacian in sampled_laplacians]\n","\n","        # forward pass \n","        output = model(feature_matrix_sampled, sampled_laplacians)\n","        \n","        loss = F.cross_entropy(output, labels[batch_nodes].to(device))\n","\n","        # compute gradients\n","        loss.backward()\n","\n","        # update parameters\n","        optimizer.step()\n","\n","        # compute accuracy\n","        acc = accuracy(output, labels[batch_nodes])\n","\n","        # append loss and accuracy\n","        train_loss.append(loss.item())\n","        train_acc.append(acc.item())\n","    \n","    end_time = time.time()\n","    elapsed_time = end_time - start_time \n","    print('Elapsed time: {:.2f} seconds'.format(elapsed_time))\n","\n","    print('Train loss: {:.4f}'.format(np.mean(train_loss)))\n","\n","    print('Train accuracy: {:.4f}'.format(np.mean(train_acc)))\n","    \n","\n","    # set model to evaluation mode\n","    model.eval()\n","\n","    val_loss = []\n","    val_acc = []\n","    \n","    feature_matrix = feature_matrix.to(device)\n","    # full batch evaluation\n","    fullbatch_laplacians = [laplacian, laplacian]\n","    fullbatch_laplacians = [laplacian.to(device) for laplacian in fullbatch_laplacians]\n","    \n","    output = model(feature_matrix, fullbatch_laplacians)\n","\n","    loss = F.cross_entropy(output[idx_val], labels[idx_val].to(device))\n","    acc = accuracy(output[idx_val], labels[idx_val])\n","    valid_f1 = f1_score(output[idx_val].argmax(dim=1).cpu(), labels[idx_val].cpu(), average='micro')\n","    print(valid_f1, 'f1-score')\n","    \n","    # save best model\n","    if valid_f1 > best_f1 :\n","        best_f1 = valid_f1\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","    # append loss and accuracy\n","    val_loss.append(loss.item())\n","    val_acc.append(acc.item())\n","\n","    print('Validation loss: {:.4f}'.format(np.mean(val_loss)))\n","    print('Validation accuracy: {:.4f}'.format(np.mean(val_acc)))    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-05T08:38:44.310733Z","iopub.status.busy":"2024-02-05T08:38:44.310338Z","iopub.status.idle":"2024-02-05T08:38:44.458831Z","shell.execute_reply":"2024-02-05T08:38:44.457961Z","shell.execute_reply.started":"2024-02-05T08:38:44.310703Z"},"trusted":true},"outputs":[],"source":["# Test the best model on the idx_test set\n","\n","model.load_state_dict(torch.load('best_model.pth'))\n","\n","model.eval()\n","\n","feature_matrix = feature_matrix.to(device)\n","\n","fullbatch_laplacians = [laplacian, laplacian]\n","fullbatch_laplacians = [laplacian.to(device) for laplacian in fullbatch_laplacians] \n","\n","# evaluation is done without sampling\n","output = model(feature_matrix, fullbatch_laplacians)\n","\n","predicted_labels = torch.argmax(output, dim=1)\n","predicted_labels = predicted_labels.type(torch.FloatTensor)\n","\n","# compute f1 score\n","\n","test_f1 = f1_score(predicted_labels[idx_test].cpu(), labels[idx_test].cpu(), average='micro')\n","\n","print('Test f1 score: {:.4f}'.format(test_f1))\n","\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2357660,"sourceId":3972659,"sourceType":"datasetVersion"},{"datasetId":4400306,"sourceId":7555375,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
